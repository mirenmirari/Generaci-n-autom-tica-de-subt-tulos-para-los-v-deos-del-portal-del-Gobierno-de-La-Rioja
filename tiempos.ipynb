{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7122a15f",
   "metadata": {},
   "source": [
    "En primer lugar instalamos y cargamos las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b800acc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jonathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jonathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube #Para descargar los videos\n",
    "from pydub import AudioSegment\n",
    "import pydub #Para trabajar con el audio\n",
    "\n",
    "from huggingsound import SpeechRecognitionModel #Para cargar el modelo\n",
    "from pocketsphinx import AudioFile, get_model_path\n",
    "import os\n",
    "\n",
    "import re #Para la parte de normalizar\n",
    "import string \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from autocorrect import Speller #Para los errores ortográficos\n",
    "spell = Speller(lang='es')\n",
    "from jiwer import wer #Para la métrica\n",
    "\n",
    "import time #para medir el tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc57d0",
   "metadata": {},
   "source": [
    "Creamos ahora las funciones que se encargan de hacer todo el proceso de transcripción y normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc6b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargarVideo(video, formato):\n",
    "    video.streams.filter(only_audio=True)\n",
    "    audio = video.streams.get_by_itag(22)\n",
    "    mp4 = audio.download()\n",
    "    audio = AudioSegment.from_file(mp4)\n",
    "    audio.export('video.'+str(formato), format=formato)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcee7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragmentos(audio, formato):\n",
    "    audio_length = len(audio) # Lo mide en milisegundos\n",
    "    \n",
    "    chunk_counter = 1\n",
    "    \n",
    "    point = 60000 # Duración de cada trozo\n",
    "    rem = 8000 # Tiempo de solapación\n",
    "    flag = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    lista = {} # Me creo un diccionario donde ir almacenando las rutas con sus chunk\n",
    "    \n",
    "    for i in range(0, 2*audio_length, point):\n",
    "        if i == 0:\n",
    "            start = 0\n",
    "            end = point\n",
    "        else:\n",
    "            start = end-rem\n",
    "            end = start+point\n",
    "        if end >= audio_length:\n",
    "            end = audio_length\n",
    "            flag = 1 # Para que pare\n",
    "        chunk = audio[start:end] # Nos quedamos con la parte del audio\n",
    "        \n",
    "        chunk_name = f'chunk_{chunk_counter}' # Le damos un nombre distinto a cada chunk\n",
    "        \n",
    "        chunk.export(chunk_name, format=formato) # Guardamos el chunk\n",
    "        lista[chunk_name+'.'+str(formato)] = chunk # Me guardo el chunk en la lista\n",
    "        chunk_counter += 1\n",
    "        if flag == 1:\n",
    "            break\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42f24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2vec(lista):\n",
    "    wav2vec = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-spanish\")\n",
    "    audio_paths = []\n",
    "    transcripciones = []\n",
    "    for i in range(1, len(lista)+1):\n",
    "        audio_paths.append(['chunk_'+str(i)])\n",
    "        transcripciones.append(wav2vec.transcribe(audio_paths[i-1]))\n",
    "    return audio_paths, transcripciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30ac739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pocketsphinx(lista):\n",
    "    model_path = get_model_path()\n",
    "    config = {\n",
    "        'verbose': False,\n",
    "        'hmm': os.path.join(model_path, 'es-es'), # Carpeta del modelo acústico\n",
    "        'lm': os.path.join(model_path, 'es-20k.lm.bin'), #Modelo de lenguaje\n",
    "        'dict': os.path.join(model_path, 'es.dict')\n",
    "    }\n",
    "    audio_paths = []\n",
    "    transcripciones = []\n",
    "    for i in range(1, len(lista)+1):\n",
    "        texto = ''\n",
    "        audio_paths.append('chunk_'+str(i))\n",
    "        audio = AudioFile(**config, audio_file = audio_paths[i-1])\n",
    "        for frase in audio:\n",
    "            texto = texto + str(frase) + ' '\n",
    "        transcripciones.append(texto)\n",
    "    return audio_paths, transcripciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b1ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenarWav2vec(transcripcion):\n",
    "    texto = transcripcion[0][0]['transcription']\n",
    "    for i in range(1, len(transcripcion)):\n",
    "        a = len(transcripcion[i][0]['transcription'])\n",
    "        j = 1 # Empiezo en 1 porque 0 será el espacio\n",
    "        esta = False\n",
    "        long = len(texto)\n",
    "        esp = texto[::-1].index(' ')\n",
    "        texto = texto[:long-esp] # Corto a partir del último espacio por si la palabra está cortada\n",
    "        esp2 = transcripcion[i][0]['transcription'].index(' ')\n",
    "        transcripcion[i][0]['transcription'] = transcripcion[i][0]['transcription'][esp2:] # Corto a partir del primer espacio por si la palabra está cortada\n",
    "        while esta == False and j<a:\n",
    "            if transcripcion[i][0]['transcription'][1:j] in texto[:]:\n",
    "                j = j+1\n",
    "            else:\n",
    "                texto = texto + transcripcion[i][0]['transcription'][j:]\n",
    "                esta = True\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359d55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenarPocketsphinx(transcripcion):\n",
    "    texto = transcripcion[0]\n",
    "    for i in range(1, len(transcripcion)):\n",
    "        a = len(transcripcion[i])\n",
    "        j = 1 # Empiezo por 1 porque 0 será espacio\n",
    "        esta = False\n",
    "        long = len(texto)\n",
    "        esp = texto[::-1].index(' ')\n",
    "        texto = texto[:long-esp] # Corto a partir del último espacio por si la palabra está cortada\n",
    "        esp2 = transcripcion[i].index(' ')\n",
    "        transcripcion[i] = transcripcion[i][esp2:] # Corto a partir del primer espacio por si la palabra está cortada\n",
    "        while esta == False and j<a:\n",
    "            if transcripcion[i][1:j] in texto[:]:\n",
    "                j = j+1\n",
    "            else:\n",
    "                texto = texto + transcripcion[i][j:]\n",
    "                esta = True\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "896879b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numero_to_letras(numero):\n",
    "\tindicador = [(\"\",\"\"),(\"mil\",\"mil\"),(\"millon\",\"millones\"),(\"mil\",\"mil\"),(\"billon\",\"billones\")]\n",
    "\tentero = int(numero)\n",
    "\tdecimal = int(round((numero - entero)*100))\n",
    " \n",
    "\tcontador = 0\n",
    "\tnumero_letras = \"\"\n",
    "\twhile entero >0:\n",
    "\t\ta = entero % 1000\n",
    "\t\tif contador == 0:\n",
    "\t\t\ten_letras = convierte_cifra(a,1).strip()\n",
    "\t\telse :\n",
    "\t\t\ten_letras = convierte_cifra(a,0).strip()\n",
    "\t\tif a==0:\n",
    "\t\t\tnumero_letras = en_letras+\" \"+numero_letras\n",
    "\t\telif a==1:\n",
    "\t\t\tif contador in (1,3):\n",
    "\t\t\t\tnumero_letras = indicador[contador][0]+\" \"+numero_letras\n",
    "\t\t\telse:\n",
    "\t\t\t\tnumero_letras = en_letras+\" \"+indicador[contador][0]+\" \"+numero_letras\n",
    "\t\telse:\n",
    "\t\t\tnumero_letras = en_letras+\" \"+indicador[contador][1]+\" \"+numero_letras\n",
    "\t\tnumero_letras = numero_letras.strip()\n",
    "\t\tcontador = contador + 1\n",
    "\t\tentero = int(entero / 1000)\n",
    "\t\n",
    "\tif decimal == 0:\n",
    "\t\tnumero_letras = numero_letras\n",
    "\telse:\n",
    "\t\tnumero_letras = numero_letras+\" con \" + str(decimal) +\"/100\"\n",
    "\n",
    "\treturn numero_letras\n",
    " \n",
    " \n",
    "def convierte_cifra(numero,sw):\n",
    "\tlista_centana = [\"\",(\"cien\",\"ciento\"),\"doscientos\",\"trescientos\",\"cuatrocientos\",\"quinientos\",\"seiscientos\",\"setecientos\",\"ochocientos\",\"novecientos\"]\n",
    "\tlista_decena = [\"\",(\"diez\",\"once\",\"doce\",\"trece\",\"catorce\",\"quince\",\"dieciseis\",\"diecisiete\",\"dieciocho\",\"diecinueve\"),\n",
    "\t\t\t\t\t(\"veinte\",\"veinti\"),(\"treinta\",\"treinta y \"),(\"cuarenta\" , \"cuarenta y \"),\n",
    "\t\t\t\t\t(\"cincuenta\" , \"cincuenta y \"),(\"sesenta\" , \"sesenta y \"),\n",
    "\t\t\t\t\t(\"setenta\" , \"setenta y \"),(\"ochenta\" , \"ochenta y \"),\n",
    "\t\t\t\t\t(\"noventa\" , \"noventa y \")\n",
    "\t\t\t\t]\n",
    "\tlista_unidad = [\"\",(\"un\" , \"uno\"),\"dos\",\"tres\",\"cuatro\",\"cinco\",\"seis\",\"siete\",\"ocho\",\"nueve\"]\n",
    "\tcentena = int (numero / 100)\n",
    "\tdecena = int((numero -(centena * 100))/10)\n",
    "\tunidad = int(numero - (centena * 100 + decena * 10))\n",
    " \n",
    "\ttexto_centena = \"\"\n",
    "\ttexto_decena = \"\"\n",
    "\ttexto_unidad = \"\"\n",
    " \n",
    "\t#Validad las centenas\n",
    "\ttexto_centena = lista_centana[centena]\n",
    "\tif centena == 1:\n",
    "\t\tif (decena + unidad)!=0:\n",
    "\t\t\ttexto_centena = texto_centena[1]\n",
    "\t\telse :\n",
    "\t \t\ttexto_centena = texto_centena[0]\n",
    " \n",
    "\t#Valida las decenas\n",
    "\ttexto_decena = lista_decena[decena]\n",
    "\tif decena == 1 :\n",
    "\t\ttexto_decena = texto_decena[unidad]\n",
    "\telif decena > 1 :\n",
    "\t\tif unidad != 0 :\n",
    "\t\t\ttexto_decena = texto_decena[1]\n",
    "\t\telse:\n",
    "\t\t\ttexto_decena = texto_decena[0]\n",
    " \t#Validar las unidades\n",
    "    \n",
    "\tif decena != 1:\n",
    " \t\ttexto_unidad = lista_unidad[unidad]\n",
    " \t\tif unidad == 1:\n",
    " \t\t\ttexto_unidad = texto_unidad[sw]\n",
    "\treturn \"%s %s %s\" %(texto_centena,texto_decena,texto_unidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead2f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(texto):\n",
    "    tokens=word_tokenize(texto) #Separa el texto por palabras\n",
    "    \n",
    "    texto = [w.lower() for w in tokens] #Pasamos las palabras a minúsculas\n",
    "    \n",
    "    texto = [texto[i].replace(' apdo.', ' apartado').replace(' art. ',' articulo ').replace(' atte.',' atentamente').replace(' avda.',' avenida').replace(' cap.',' capítulo').replace(' cía.',' compañía').replace(' coord.',' coordinador').replace(' d.',' don').replace(' dña.',' doña').replace(' dcho.',' derecho').replace(' dcha.',' derecha').replace(' depto.',' departamento').replace(' dr.',' doctor').replace(' dra.',' doctora').replace(' etc.',' etcétera').replace(' fdo.',' firmado').replace(' izqdo.',' izquierdo').replace(' izqda.',' izquierda').replace(' max.',' máximo').replace(' min.',' mínimo').replace(' núm.',' número').replace(' pág.',' página').replace(' ej.',' ejemplo').replace(' prov.',' provincia').replace(' sr.',' señor').replace(' sra.',' señora').replace(' srta.',' señorita').replace(' tfno.',' teléfono') for i in range(len(texto))] #quitamos las abreviaciones\n",
    "    for i in range(len(texto)):\n",
    "        if texto[i].isdigit() and (texto[i] not in string.punctuation):\n",
    "            texto[i]=numero_to_letras(int(texto[i]))\n",
    "            tokens2=word_tokenize(texto[i])\n",
    "            for j in range(len(tokens2)-1):\n",
    "                texto.append('a') #me añado esto simplemente para no tener problemas con el rango\n",
    "            for j in range(i+1, len(texto)-3):\n",
    "                texto[len(texto)-j+i]=texto[len(texto)-j+i-len(tokens2)+1]\n",
    "            for j in range(i, i+len(tokens2)-1):\n",
    "                texto[j+len(tokens2)-1] = texto[j]\n",
    "            for j in range(i, i+len(tokens2)):\n",
    "                texto[j]=tokens2[j-i]\n",
    "    tokens=[w.lower() for w in texto] #Pasamos las palabras a minúsculas por si había números\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    stripped = [re_punc.sub('',w) for w in tokens]\n",
    "    stripped=[stripped[i].replace('¿', '').replace('¡','').replace(\"'\",'') for i in range(len(tokens))] #quita los símbolos de puntuación que string.punctuation no tiene en cuenta\n",
    "    words = [word for word in stripped if word.isalpha()] #Elimina los signos de puntuación\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c0006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortografia(texto):\n",
    "    for word in texto:\n",
    "        word = spell(word)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc3f78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unir(texto):\n",
    "    texto_norm = \"\"\n",
    "    for i in range(len(texto)):\n",
    "        texto_norm = texto_norm + ' ' + texto[i]\n",
    "    return texto_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1729c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcripcion(video, modelo, formato):\n",
    "    inicio = time.time() # Para calcular el tiempo que tarda en ejecutarse\n",
    "    audio = cargarVideo(video, formato)\n",
    "    lista = fragmentos(audio, formato)\n",
    "    if modelo==wav2vec:\n",
    "        audio_paths, transcripciones = wav2vec(lista)\n",
    "        texto = concatenarWav2vec(transcripciones)\n",
    "    elif modelo==pocketsphinx:\n",
    "        audio_paths, transcripciones = pocketsphinx(lista)\n",
    "        texto = concatenarPocketsphinx(transcripciones)\n",
    "    else:\n",
    "        print('El modelo elegido no funciona.')\n",
    "    normalizado = normalizar(texto)\n",
    "    ortog = ortografia(normalizado)\n",
    "    texto_norm = unir(ortog)\n",
    "    fin = time.time()\n",
    "    tiempo = fin-inicio\n",
    "    return texto_norm, tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921a3a5",
   "metadata": {},
   "source": [
    "Cargamos el vídeo y le aplicamos la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "560e1a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/16/2022 13:11:12 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:36<00:00, 36.58s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:35<00:00, 35.66s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:36<00:00, 36.25s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:36<00:00, 36.16s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:35<00:00, 35.91s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:35<00:00, 35.45s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:36<00:00, 36.34s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:34<00:00, 34.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306.5403685569763\n"
     ]
    }
   ],
   "source": [
    "video = YouTube('https://www.youtube.com/watch?v=YwMyCV6UzRU')\n",
    "texto, tiempo = transcripcion(video, wav2vec, 'wav')\n",
    "print(tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a70ea53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522.1310942173004\n"
     ]
    }
   ],
   "source": [
    "texto, tiempo = transcripcion(video, pocketsphinx, 'raw')\n",
    "print(tiempo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
